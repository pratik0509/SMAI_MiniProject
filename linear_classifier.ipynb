{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "class linear_classifier:\n",
    "    def __init__(self, train_path, test_path, q=4):\n",
    "        self.quantization = q\n",
    "        self.train_path = train_path\n",
    "        self.test_path = test_path\n",
    "        self.raw_train_data = None\n",
    "        self.raw_train_data_shape = None\n",
    "        self.raw_train_data_size = None\n",
    "        self.raw_train_labels = None\n",
    "        self.train_label_map = None\n",
    "        self.train_label_num = None\n",
    "        self.class_train_labels = None\n",
    "        self.train_weights = None\n",
    "        self.weights = np.array([])\n",
    "        self.eigen_values = np.array([])\n",
    "        self.eigen_vectors = np.array([])\n",
    "        return\n",
    "    \n",
    "    def read_train_data(self):\n",
    "        self.raw_train_data = np.array([])\n",
    "        self.raw_train_labels = np.array([])\n",
    "        self.train_label_map = {}\n",
    "        self.train_label_imap = {}\n",
    "        self.train_label_num = 0\n",
    "        with open(self.train_path) as fp:\n",
    "            line = fp.readline().strip('\\n')\n",
    "            elem_shape = []\n",
    "            num_elem = 0\n",
    "            while line:\n",
    "                line = line.split(' ')\n",
    "                num_elem += 1\n",
    "                img = np.asarray(Image.open(line[0].strip('\\n')).convert('L'))\n",
    "                img_shape = np.shape(img)\n",
    "                img = np.reshape(img, [img_shape[0]*img_shape[1], 1])\n",
    "                elem_shape = img_shape\n",
    "                if not line[1].strip('\\n') in self.train_label_map:\n",
    "                    self.train_label_map[line[1].rstrip('\\n')] = self.train_label_num\n",
    "                    self.train_label_imap[self.train_label_num] = line[1].strip('\\n')\n",
    "                    self.train_label_num += 1\n",
    "                if self.raw_train_data.size == 0:\n",
    "                    self.raw_train_data = img\n",
    "                    self.raw_train_labels = np.array([line[1].strip('\\n')])\n",
    "                else:\n",
    "                    self.raw_train_data = np.concatenate([self.raw_train_data, img], axis=1)\n",
    "                    self.raw_train_labels = np.concatenate([self.raw_train_labels, np.array([line[1].strip('\\n')])])\n",
    "                line = fp.readline().strip('\\n')\n",
    "            self.raw_train_data_shape = elem_shape\n",
    "            self.raw_train_data_size = num_elem\n",
    "        return\n",
    "    \n",
    "    def pca(self):\n",
    "        sz = np.shape(self.raw_train_data)\n",
    "        M = np.mean(self.raw_train_data, axis=0)\n",
    "        CX = self.raw_train_data - M\n",
    "        COV = CX.T.dot(CX)\n",
    "        eigen_values, eigen_vecs = np.linalg.eig(COV)\n",
    "        pseudo_eigen_vecs = CX.dot(eigen_vecs)\n",
    "        data = []\n",
    "        for idx, val in enumerate(eigen_values):\n",
    "            data.append((np.array(val), np.reshape(pseudo_eigen_vecs[:, idx], [sz[0], 1])))\n",
    "        data.sort(key=lambda pair: pair[0], reverse=True)\n",
    "        for val in data:\n",
    "            if self.eigen_values.size == 0:\n",
    "                self.eigen_values = np.array([val[0]])\n",
    "                self.eigen_vectors = np.array(val[1])\n",
    "            else:\n",
    "                self.eigen_values = np.concatenate([self.eigen_values, np.array([val[0]])])\n",
    "                self.eigen_vectors = np.concatenate([self.eigen_vectors, val[1]], axis=1)\n",
    "        return\n",
    "\n",
    "    def project_samples(self, num_comp=-1):\n",
    "        if num_comp == -1:\n",
    "            num_comp = np.shape(self.raw_train_data)[1]\n",
    "        reduced_samples = np.array([])\n",
    "        M = np.mean(self.raw_train_data, axis=0)\n",
    "        C_values = self.raw_train_data - M\n",
    "        self.raw_train_data_mean = np.copy(M)\n",
    "        for v in self.eigen_vectors.T[0:num_comp]:\n",
    "            abs_v = np.sum(np.sqrt(np.square(v)))\n",
    "            v = v / abs_v\n",
    "            alpha = np.array([v]).dot(C_values)\n",
    "            if reduced_samples.size == 0:\n",
    "                reduced_samples = alpha\n",
    "            else:\n",
    "                reduced_samples = np.concatenate([reduced_samples, alpha])\n",
    "        self.transformed_data = np.copy(reduced_samples)\n",
    "        return reduced_samples\n",
    "     \n",
    "    def soft_max(self, X):\n",
    "        stable_x = X - np.max(X)\n",
    "        exp_x = np.exp(stable_x)\n",
    "        return exp_x / np.sum(exp_x, axis = 0)\n",
    "    \n",
    "    def regression(self, eta, num_iter, num_comp=32, max_err=0):\n",
    "        C = 0.00002\n",
    "        self.weights = np.random.rand(self.train_label_num, num_comp)\n",
    "        prev_wts = np.zeros_like(self.weights)\n",
    "        labels = np.array([self.train_label_map[x] for x in self.raw_train_labels])\n",
    "        diff_wts = self.weights - prev_wts\n",
    "        itr = 0\n",
    "        while itr < num_iter and max_err < np.sqrt(np.sum(diff_wts*diff_wts)):\n",
    "            weight_labels = self.soft_max(np.matmul(self.weights, self.transformed_data))\n",
    "            weight_labels[labels[:], np.arange(self.raw_train_data_size)] -= 1.0\n",
    "            J = np.matmul(weight_labels, self.transformed_data.T) / self.raw_train_data_size + C * self.weights\n",
    "            prev_wts = np.copy(self.weights)\n",
    "            self.weights -= eta * J\n",
    "            diff_wts = self.weights - prev_wts\n",
    "            itr += 1\n",
    "        return\n",
    "        \n",
    "    def read_test_data(self, path):\n",
    "        X = np.array([])\n",
    "        with open(path) as fp:\n",
    "            line = fp.readline().strip('\\n')\n",
    "            while line:\n",
    "                line = line.split(' ')\n",
    "                img = np.asarray(Image.open(line[0]).convert('L'))\n",
    "                img_shape = np.shape(img)\n",
    "                img = np.reshape(img, [img_shape[0]*img_shape[1], 1])\n",
    "                elem_shape = img_shape\n",
    "                if X.size == 0:\n",
    "                    X = img\n",
    "                else:\n",
    "                    X = np.concatenate([X, img], axis=1)\n",
    "                line = fp.readline().strip('\\n')\n",
    "        return X\n",
    "    \n",
    "    def center_data(self, X):\n",
    "        CX = X - np.mean(X, axis=0)\n",
    "        return CX\n",
    "    \n",
    "    def reduce_test_samples(self, CX, num_comp):\n",
    "        reduced_sample = np.array([]) \n",
    "        for v in self.eigen_vectors.T[0:num_comp]:\n",
    "            abs_v = np.sum(np.sqrt(np.square(v)))\n",
    "            v = v / abs_v\n",
    "            alpha = np.array([v]).dot(CX)\n",
    "            if reduced_sample.size == 0:\n",
    "                reduced_sample = alpha\n",
    "            else:\n",
    "                reduced_sample = np.concatenate([reduced_sample, alpha])\n",
    "        return reduced_sample\n",
    "    \n",
    "    def predict(self, test_file_path, num_comp):\n",
    "        X = self.read_test_data(test_file_path)\n",
    "        CX = self.center_data(X)\n",
    "        RX = self.reduce_test_samples(CX, num_comp)\n",
    "        P = []\n",
    "        for val in RX.T:\n",
    "            P.append(self.train_label_imap[np.argmax(self.soft_max(np.matmul(self.weights, np.array(val))))])\n",
    "        return P\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '-f'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ef7258305f34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# test_file = './train_sample3.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_train_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproject_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-1f84fdfe6187>\u001b[0m in \u001b[0;36mread_train_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_label_imap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_label_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0melem_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '-f'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "train_file = sys.argv[1]\n",
    "test_file = sys.argv[2]\n",
    "#     Remove comments when actually running\n",
    "# train_file = './train_sample.txt'\n",
    "# test_file = './train_sample3.txt'\n",
    "model = linear_classifier(train_file, test_file, 10)\n",
    "model.read_train_data()\n",
    "model.pca()\n",
    "_ = model.project_samples(32)\n",
    "model.regression(0.003, 500000, 32, 0.000002)\n",
    "pred_labels = model.predict(test_file, 32)\n",
    "\n",
    "for i in pred_labels:\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
