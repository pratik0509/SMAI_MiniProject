{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "class naive_bayes:\n",
    "    def __init__(self, train_path, test_path, q=4):\n",
    "        self.quantization = q\n",
    "        self.train_path = train_path\n",
    "        self.test_path = test_path\n",
    "        self.raw_train_data = None\n",
    "        self.raw_train_data_shape = None\n",
    "        self.raw_train_data_size = None\n",
    "        self.raw_train_labels = None\n",
    "        self.train_label_map = None\n",
    "        self.train_label_num = None\n",
    "        self.class_train_labels = None\n",
    "        self.eigen_values = np.array([])\n",
    "        self.eigen_vectors = np.array([])\n",
    "        self.class_boundary = {}\n",
    "        return\n",
    "    \n",
    "    def read_train_data(self):\n",
    "        self.raw_train_data = np.array([])\n",
    "        self.raw_train_labels = np.array([])\n",
    "        self.train_label_map = {}\n",
    "        self.train_label_imap = {}\n",
    "        self.train_label_num = 0\n",
    "        with open(self.train_path) as fp:\n",
    "            line = fp.readline().strip('\\n')\n",
    "            elem_shape = []\n",
    "            num_elem = 0\n",
    "            while line:\n",
    "                line = line.split(' ')\n",
    "                num_elem += 1\n",
    "                img = np.asarray(Image.open(line[0].strip('\\n')).convert('L'))\n",
    "                img_shape = np.shape(img)\n",
    "                img = np.reshape(img, [img_shape[0]*img_shape[1], 1])\n",
    "                elem_shape = img_shape\n",
    "                if not line[1].strip('\\n') in self.train_label_map:\n",
    "                    self.train_label_map[line[1].rstrip('\\n')] = self.train_label_num\n",
    "                    self.train_label_imap[self.train_label_num] = line[1].strip('\\n')\n",
    "                    self.train_label_num += 1\n",
    "                if self.raw_train_data.size == 0:\n",
    "                    self.raw_train_data = img\n",
    "                    self.raw_train_labels = np.array([line[1].strip('\\n')])\n",
    "                else:\n",
    "                    self.raw_train_data = np.concatenate([self.raw_train_data, img], axis=1)\n",
    "                    self.raw_train_labels = np.concatenate([self.raw_train_labels, np.array([line[1].strip('\\n')])])\n",
    "                line = fp.readline().strip('\\n')\n",
    "            self.raw_train_data_shape = elem_shape\n",
    "            self.raw_train_data_size = num_elem\n",
    "        return\n",
    "    \n",
    "    def pca(self):\n",
    "        sz = np.shape(self.raw_train_data)\n",
    "        M = np.mean(self.raw_train_data, axis=0)\n",
    "        CX = self.raw_train_data - M\n",
    "        COV = CX.T.dot(CX)\n",
    "        eigen_values, eigen_vecs = np.linalg.eig(COV)\n",
    "        pseudo_eigen_vecs = CX.dot(eigen_vecs)\n",
    "        data = []\n",
    "        for idx, val in enumerate(eigen_values):\n",
    "            data.append((np.array(val), np.reshape(pseudo_eigen_vecs[:, idx], [sz[0], 1])))\n",
    "        data.sort(key=lambda pair: pair[0], reverse=True)\n",
    "        for val in data:\n",
    "            if self.eigen_values.size == 0:\n",
    "                self.eigen_values = np.array([val[0]])\n",
    "                self.eigen_vectors = np.array(val[1])\n",
    "            else:\n",
    "                self.eigen_values = np.concatenate([self.eigen_values, np.array([val[0]])])\n",
    "                self.eigen_vectors = np.concatenate([self.eigen_vectors, val[1]], axis=1)\n",
    "        return\n",
    "\n",
    "    def project_samples(self, num_comp=-1):\n",
    "        if num_comp == -1:\n",
    "            num_comp = np.shape(self.raw_train_data)[1]\n",
    "        reduced_samples = np.array([])\n",
    "        M = np.mean(self.raw_train_data, axis=0)\n",
    "        C_values = self.raw_train_data - M\n",
    "        self.raw_train_data_mean = np.copy(M)\n",
    "        for v in self.eigen_vectors.T[0:num_comp]:\n",
    "            abs_v = np.sum(np.sqrt(np.square(v)))\n",
    "            v = v / abs_v\n",
    "            alpha = np.array([v]).dot(C_values)\n",
    "            if reduced_samples.size == 0:\n",
    "                reduced_samples = alpha\n",
    "            else:\n",
    "                reduced_samples = np.concatenate([reduced_samples, alpha])\n",
    "        self.transformed_data = np.copy(reduced_samples)\n",
    "        return reduced_samples\n",
    "    \n",
    "    def divide_class(self, num_comp=-1):\n",
    "        if num_comp == -1:\n",
    "            num_comp = np.shape(self.raw_train_data)[1]\n",
    "        sorted_values = self.project_samples(num_comp)\n",
    "        sorted_values.sort(axis=1)\n",
    "        index = int(self.raw_train_data_size // self.quantization)\n",
    "        num_rows = self.raw_train_data_shape[0]\n",
    "        for i in range(0, num_comp):\n",
    "            self.class_boundary[i] = []\n",
    "            for j in range(1, self.quantization):\n",
    "                self.class_boundary[i].append((sorted_values[i,index*j] + sorted_values[i,index*j-1])/2)\n",
    "        return\n",
    "\n",
    "    def relabel_train_data(self, num_comp=-1):\n",
    "        if num_comp == -1:\n",
    "            num_comp = np.shape(self.raw_train_data)[1]\n",
    "        self.class_train_labels = np.zeros_like(self.raw_train_data[0:num_comp, :])\n",
    "        for i in range(0, num_comp):\n",
    "            for j in range(0, self.raw_train_data_size):\n",
    "                for k in range(0, self.quantization-1):\n",
    "                    if self.transformed_data[i, j] < self.class_boundary[i][k]:\n",
    "                        self.class_train_labels[i,j] = k+1\n",
    "                        break\n",
    "                if not self.transformed_data[i, j] < self.class_boundary[i][self.quantization-2]:\n",
    "                    self.class_train_labels[i, j] = self.quantization\n",
    "        return\n",
    "    \n",
    "    def calculate_probabilities(self):\n",
    "        self.class_probabilities = np.zeros([np.shape(self.class_train_labels)[0], self.train_label_num, self.quantization+1])\n",
    "        self.class_samples = np.zeros([np.shape(self.class_train_labels)[0], self.train_label_num])\n",
    "        for i, row in enumerate(self.class_train_labels):\n",
    "            for j, col in enumerate(row):\n",
    "                self.class_probabilities[i, self.train_label_map[self.raw_train_labels[j]], self.class_train_labels[i,j]] += 1\n",
    "                self.class_samples[i, self.train_label_map[self.raw_train_labels[j]]] += 1\n",
    "        \n",
    "        for i in range(1, self.quantization+1):\n",
    "            self.class_probabilities[:, :, i] = self.class_probabilities[:, :, i] / self.class_samples\n",
    "        return\n",
    "    \n",
    "    def read_test_data(self, path):\n",
    "        X = np.array([])\n",
    "        with open(path) as fp:\n",
    "            line = fp.readline().strip('\\n')\n",
    "            while line:\n",
    "                line = line.split(' ')\n",
    "                img = np.asarray(Image.open(line[0]).convert('L'))\n",
    "                img_shape = np.shape(img)\n",
    "                img = np.reshape(img, [img_shape[0]*img_shape[1], 1])\n",
    "                elem_shape = img_shape\n",
    "                if X.size == 0:\n",
    "                    X = img\n",
    "                else:\n",
    "                    X = np.concatenate([X, img], axis=1)\n",
    "                line = fp.readline().strip('\\n')\n",
    "        return X\n",
    "    \n",
    "    def center_data(self, X):\n",
    "        CX = X - np.mean(X, axis=0)\n",
    "        return CX\n",
    "    \n",
    "    def reduce_test_samples(self, CX, num_comp):\n",
    "        reduced_sample = np.array([]) \n",
    "        for v in self.eigen_vectors.T[0:num_comp]:\n",
    "            abs_v = np.sum(np.sqrt(np.square(v)))\n",
    "            v = v / abs_v\n",
    "            alpha = np.array([v]).dot(CX)\n",
    "            if reduced_sample.size == 0:\n",
    "                reduced_sample = alpha\n",
    "            else:\n",
    "                reduced_sample = np.concatenate([reduced_sample, alpha])\n",
    "        return reduced_sample\n",
    "\n",
    "    def relabel_data(self, X, num_comp):\n",
    "        r_X = np.zeros_like(X)\n",
    "        for i in range(0, num_comp):\n",
    "            for j in range(0, np.shape(X)[1]):\n",
    "                for k in range(0, self.quantization-1):\n",
    "                    if X[i,j] < self.class_boundary[i][k]:\n",
    "                        r_X[i,j] = k+1\n",
    "                        break\n",
    "                if not X[i,j] < self.class_boundary[i][self.quantization-2]:\n",
    "                    r_X[i,j] = self.quantization\n",
    "        return r_X\n",
    "\n",
    "    def get_predicted_label(self, X, num_comp):\n",
    "        probabilities = np.ones([self.train_label_num, np.shape(X)[1]])\n",
    "        for i in range(0, num_comp):\n",
    "            for j in range(0, np.shape(X)[1]):\n",
    "                for k in range(0, self.train_label_num):\n",
    "                    probabilities[k, j] = probabilities[k, j]*self.class_probabilities[i, k, int(X[i, j])]\n",
    "        \n",
    "        label = np.argmax(probabilities, axis = 0)\n",
    "        rev_label = []\n",
    "        for i in label:\n",
    "            rev_label.append(self.train_label_imap[i])\n",
    "        return rev_label\n",
    "   \n",
    "    def predict(self, path):\n",
    "        X = self.read_test_data(path)\n",
    "        CX = self.center_data(X)\n",
    "        RX = self.reduce_test_samples(CX, 32)\n",
    "        LX = self.relabel_data(RX, 32)\n",
    "        P = self.get_predicted_label(LX, 32)\n",
    "        return P\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '-f'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d836f6320232>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# test_file = './problem_statement/sample_test.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnaive_bayes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_train_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdivide_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-df0a6500e064>\u001b[0m in \u001b[0;36mread_train_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_label_imap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_label_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0melem_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '-f'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "train_file = sys.argv[1]\n",
    "test_file = sys.argv[2]\n",
    "#     Remove comments when actually running\n",
    "#     train_file = './problem_statement/sample_train.txt'\n",
    "# train_file = './train_sample.txt'\n",
    "# test_file = './problem_statement/sample_test.txt'\n",
    "model = naive_bayes(train_file, test_file, 10)\n",
    "model.read_train_data()\n",
    "model.pca()\n",
    "model.divide_class(32)\n",
    "model.relabel_train_data(32)\n",
    "model.calculate_probabilities()\n",
    "pred_labels = model.predict(test_file)\n",
    "\n",
    "for i in pred_labels:\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
